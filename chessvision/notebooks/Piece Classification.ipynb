{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Piece Classification Results\n",
    "\n",
    "A 13xN grid of classified training data.\n",
    "\n",
    "N is the minimum number of examples predicted by the model on the current batch. \n",
    "(Discover if train_generator is very uneven.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'theano'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b7110d94eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_validation_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         valid_datagen = ImageDataGenerator(\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using Theano backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtheano_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrng_mrg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMRG_RandomStreams\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mRandomStreams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'theano'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv_globals\n",
    "\n",
    "def get_validation_generator():\n",
    "        valid_datagen = ImageDataGenerator(\n",
    "                rescale=1./255\n",
    "                )\n",
    "        valid_generator = valid_datagen.flow_from_directory(\n",
    "        '../data/squares/validation/',\n",
    "        target_size=cv_globals.PIECE_SIZE,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "        return valid_generator\n",
    "\n",
    "def get_train_generator():\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                samplewise_center=False,\n",
    "                rotation_range=10,\n",
    "                zoom_range=0.05,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=5\n",
    "                )\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                '../data/squares/training/',\n",
    "                target_size=cv_globals.PIECE_SIZE,\n",
    "                color_mode='grayscale',\n",
    "                batch_size=32,\n",
    "                class_mode='categorical')\n",
    "        return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from square_classifier import build_square_classifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 13\n",
    "batch_size = 300\n",
    "\n",
    "# input image dimensions\n",
    "input_shape = (64, 64, 1)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "        )\n",
    "\n",
    "# Class weighting\n",
    "\n",
    "# Even out classes or leave as \"in the wild?\"\n",
    "\n",
    "#https://stackoverflow.com/questions/44666910/keras-image-preprocessing-unbalanced-data\n",
    "#https://stackoverflow.com/questions/42586475/is-it-possible-to-automatically-infer-the-class-weight-from-flow-from-directory\n",
    "#train_datagen.fit()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../../data/squares/validation',\n",
    "        target_size=(64, 64),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Build the model\n",
    "model = build_square_classifier()\n",
    "model.load_weights(\"../../weights/best_weights_square.hdf5\")\n",
    "\n",
    "# Get a batch of training data\n",
    "im_batch, _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_batch, _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict a batch & compute min \n",
    "from collections import Counter\n",
    "\n",
    "label_names  = ['B', 'K', 'N', 'P', 'Q', 'R', 'b', 'k', 'n', 'p', 'q', 'r', 'f']\n",
    "\n",
    "class_probs = model.predict(im_batch)\n",
    "predictions = np.argmax(class_probs, axis=1)\n",
    "pred_labels = [label_names[p] for p in predictions]\n",
    "\n",
    "# Get the minimum number of predictions for each class\n",
    "counter = Counter(pred_labels)                          \n",
    "num_sq = int(min(counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a grid of pieces\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "rows = num_classes\n",
    "cols = num_sq\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 12))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 share_all=True,\n",
    "                 label_mode=None\n",
    "                 )\n",
    "\n",
    "for i, class_name in enumerate(label_names):\n",
    "    k = 0\n",
    "    for j in range(cols):\n",
    "        # get a new image from im_batch with pred_label class_name\n",
    "        while pred_labels[k] != class_name:\n",
    "            k += 1\n",
    "        ax = grid[cols*i+j]\n",
    "        ax.imshow(im_batch[k].reshape(64, 64), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        k += 1\n",
    "\n",
    "#plt.savefig(\"../../img/training_classification11.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data results\n",
    "\n",
    "- get batch of raw images (N=5)\n",
    "- extract boards\n",
    "- extract squares (N * 64) -> batch\n",
    "- same as above: count min_sq and plot a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import listdir_nohidden\n",
    "from board_extractor import extract_board\n",
    "from extract_squares import extract_squares\n",
    "import cv2 \n",
    "import u_net as unet\n",
    "\n",
    "num_boards = 15\n",
    "\n",
    "raw_dir = \"../../data/raw/\"\n",
    "raw_imgs = listdir_nohidden(raw_dir)\n",
    "raw_batch = np.random.choice(raw_imgs, num_boards)\n",
    "\n",
    "raw_imgs = list(map(lambda f: cv2.imread(raw_dir + f), raw_batch))\n",
    "resized_imgs = list(map(lambda im: cv2.resize(im, (256, 256), interpolation=cv2.INTER_AREA), raw_imgs))\n",
    "\n",
    "extract_model = unet.get_unet_256()\n",
    "extract_model.load_weights('../../weights/best_weights.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of boards\n",
    "\n",
    "boards = []\n",
    "for raw_img, resized_img in zip(raw_imgs, resized_imgs):\n",
    "    try:\n",
    "        board = extract_board(resized_img, raw_img, extract_model)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    boards.append(board)\n",
    "\n",
    "# transform to a batch of squares\n",
    "square_batch = []\n",
    "for b in boards:\n",
    "    squares, _ = extract_squares(b)\n",
    "    square_batch.append(squares)\n",
    "\n",
    "square_batch = np.array(square_batch)\n",
    "square_batch = np.reshape(square_batch, (num_boards*64, 64, 64, 1))\n",
    "print(square_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_probs = model.predict(square_batch)\n",
    "predictions = np.argmax(class_probs, axis=1)\n",
    "pred_labels = [label_names[p] for p in predictions]\n",
    "\n",
    "# Get the minimum number of predictions for each class\n",
    "counter = Counter(pred_labels)                          \n",
    "num_sq = int(min(counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = num_sq\n",
    "rows = num_classes\n",
    "\n",
    "fig = plt.figure(2, figsize=(12, 12))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 share_all=True,\n",
    "                 label_mode=None\n",
    "                 )\n",
    "\n",
    "for i, class_name in enumerate(label_names):\n",
    "    k = 0\n",
    "    for j in range(cols):\n",
    "        # get a new image from im_batch with pred_label class_name\n",
    "        while pred_labels[k] != class_name:\n",
    "            k += 1\n",
    "        ax = grid[cols*i+j]\n",
    "        ax.imshow(square_batch[k].reshape(64, 64), cmap=\"gray\")\n",
    "        if j == 0:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_ylabel(class_name, rotation=\"horizontal\", labelpad=10.0, size=11)\n",
    "        else: \n",
    "            ax.axis(\"off\")\n",
    "            \n",
    "        \n",
    "        k += 1\n",
    "#plt.suptitle(\"Classification of extracted boards from test set\")\n",
    "plt.savefig(\"../../img/test_classification.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
